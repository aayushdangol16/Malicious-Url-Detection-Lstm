{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlUAAAGwCAYAAACAZ5AeAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAApDUlEQVR4nO3df1RU953/8deADqA4uCg/woo/sqZVGn9UVJzd1hMT1klCcuIRrWY9hijaExdtcRpFdi1oNnvMmm3VFH+061Gy58RG7a52lYrxYMVsJJJgSdUGN+mhB3NwAJvAKBVQ4PtHDvfLRBKQfHTAeT7OmXMy937mzhva0eeZuXO1tbe3twsAAABfS5C/BwAAALgfEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGDPD3AIGkra1N1dXVGjJkiGw2m7/HAQAAPdDe3q5r164pLi5OQUFf/n4UUXUPVVdXKz4+3t9jAACAXrh8+bJGjBjxpfuJqntoyJAhkj7/H8XhcPh5GgAA0BNer1fx8fHW3+Nfhqi6hzo+8nM4HEQVAAD9THen7nCiOgAAgAFEFQAAgAFEFQAAgAFEFQAAgAFEFQAAgAFEFQAAgAFEFQAAgAFEFQAAgAFEFQAAgAFEFQAAgAFEFQAAgAFEFQAAgAFEFQAAgAFEFQAAgAFEFQAAgAED/D0AAoNto83fI+Aeas9t9/cIAHDP8U4VAACAAUQVAACAAUQVAACAAUQVAACAAUQVAACAAUQVAACAAUQVAACAAUQVAACAAUQVAACAAUQVAACAAUQVAACAAUQVAACAAUQVAACAAUQVAACAAUQVAACAAUQVAACAAUQVAACAAUQVAACAAUQVAACAAUQVAACAAUQVAACAAUQVAACAAUQVAACAAUQVAACAAUQVAACAAUQVAACAAUQVAACAAUQVAACAAUQVAACAAUQVAACAAUQVAACAAUQVAACAAX6Nqg0bNshms/ncxo0bZ+1vampSRkaGhg0bpvDwcKWmpqqmpsbnGFVVVUpJSdGgQYMUHR2tNWvW6NatWz5rTp06pSlTpigkJERjx45Vfn7+bbNs375do0ePVmhoqJKSklRaWuqzvyezAACAwOX3d6q+9a1v6cqVK9btf//3f619q1ev1pEjR3Tw4EEVFxerurpac+fOtfa3trYqJSVFLS0tOnPmjF5//XXl5+crJyfHWlNZWamUlBTNmjVL5eXlyszM1LJly3T8+HFrzf79++V2u5Wbm6tz585p0qRJcrlcqq2t7fEsAAAgsNna29vb/fXkGzZs0OHDh1VeXn7bvoaGBkVFRWnfvn2aN2+eJKmiokLjx49XSUmJZsyYoWPHjumpp55SdXW1YmJiJEm7du1SVlaW6urqZLfblZWVpYKCAl24cME69sKFC1VfX6/CwkJJUlJSkqZNm6a8vDxJUltbm+Lj47Vq1SqtW7euR7P0hNfrVUREhBoaGuRwOHr9e+uPbBtt/h4B91B7rt/+WAEA43r697ff36n66KOPFBcXpwcffFCLFi1SVVWVJKmsrEw3b95UcnKytXbcuHEaOXKkSkpKJEklJSWaMGGCFVSS5HK55PV6dfHiRWtN52N0rOk4RktLi8rKynzWBAUFKTk52VrTk1m60tzcLK/X63MDAAD3J79GVVJSkvLz81VYWKidO3eqsrJS3/3ud3Xt2jV5PB7Z7XYNHTrU5zExMTHyeDySJI/H4xNUHfs79n3VGq/Xqxs3bujq1atqbW3tck3nY3Q3S1c2bdqkiIgI6xYfH9+zXwwAAOh3BvjzyZ944gnrvydOnKikpCSNGjVKBw4cUFhYmB8nMyM7O1tut9u67/V6CSsAAO5Tfv/4r7OhQ4fqG9/4hj7++GPFxsaqpaVF9fX1PmtqamoUGxsrSYqNjb3tG3gd97tb43A4FBYWpuHDhys4OLjLNZ2P0d0sXQkJCZHD4fC5AQCA+1Ofiqrr16/rj3/8ox544AElJiZq4MCBKioqsvZfunRJVVVVcjqdkiSn06nz58/7fEvvxIkTcjgcSkhIsNZ0PkbHmo5j2O12JSYm+qxpa2tTUVGRtaYnswAAgMDm14//XnzxRT399NMaNWqUqqurlZubq+DgYD377LOKiIhQenq63G63IiMj5XA4tGrVKjmdTuvbdrNnz1ZCQoIWL16szZs3y+PxaP369crIyFBISIgk6YUXXlBeXp7Wrl2rpUuX6uTJkzpw4IAKCgqsOdxut9LS0jR16lRNnz5dW7duVWNjo5YsWSJJPZoFAAAENr9G1SeffKJnn31Wf/7znxUVFaXvfOc7evfddxUVFSVJ2rJli4KCgpSamqrm5ma5XC7t2LHDenxwcLCOHj2qFStWyOl0avDgwUpLS9NLL71krRkzZowKCgq0evVqbdu2TSNGjNDu3bvlcrmsNQsWLFBdXZ1ycnLk8Xg0efJkFRYW+py83t0sAAAgsPn1OlWBhutUIVBwnSoA95N+c50qAACA+wFRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYECfiapXXnlFNptNmZmZ1rampiZlZGRo2LBhCg8PV2pqqmpqanweV1VVpZSUFA0aNEjR0dFas2aNbt265bPm1KlTmjJlikJCQjR27Fjl5+ff9vzbt2/X6NGjFRoaqqSkJJWWlvrs78ksAAAgcPWJqHrvvff085//XBMnTvTZvnr1ah05ckQHDx5UcXGxqqurNXfuXGt/a2urUlJS1NLSojNnzuj1119Xfn6+cnJyrDWVlZVKSUnRrFmzVF5erszMTC1btkzHjx+31uzfv19ut1u5ubk6d+6cJk2aJJfLpdra2h7PAgAAAputvb293Z8DXL9+XVOmTNGOHTv08ssva/Lkydq6dasaGhoUFRWlffv2ad68eZKkiooKjR8/XiUlJZoxY4aOHTump556StXV1YqJiZEk7dq1S1lZWaqrq5PdbldWVpYKCgp04cIF6zkXLlyo+vp6FRYWSpKSkpI0bdo05eXlSZLa2toUHx+vVatWad26dT2apSe8Xq8iIiLU0NAgh8Nh7HfYH9g22vw9Au6h9ly//rECAEb19O9vv79TlZGRoZSUFCUnJ/tsLysr082bN322jxs3TiNHjlRJSYkkqaSkRBMmTLCCSpJcLpe8Xq8uXrxorfnisV0ul3WMlpYWlZWV+awJCgpScnKytaYns3SlublZXq/X5wYAAO5PA/z55G+++abOnTun995777Z9Ho9HdrtdQ4cO9dkeExMjj8djrekcVB37O/Z91Rqv16sbN27os88+U2tra5drKioqejxLVzZt2qSNGzd+6X4AAHD/8Ns7VZcvX9YPf/hDvfHGGwoNDfXXGHdVdna2GhoarNvly5f9PRIAALhL/BZVZWVlqq2t1ZQpUzRgwAANGDBAxcXFeu211zRgwADFxMSopaVF9fX1Po+rqalRbGysJCk2Nva2b+B13O9ujcPhUFhYmIYPH67g4OAu13Q+RnezdCUkJEQOh8PnBgAA7k9+i6rHHntM58+fV3l5uXWbOnWqFi1aZP33wIEDVVRUZD3m0qVLqqqqktPplCQ5nU6dP3/e51t6J06ckMPhUEJCgrWm8zE61nQcw263KzEx0WdNW1ubioqKrDWJiYndzgIAAAKb386pGjJkiB5++GGfbYMHD9awYcOs7enp6XK73YqMjJTD4dCqVavkdDqtb9vNnj1bCQkJWrx4sTZv3iyPx6P169crIyNDISEhkqQXXnhBeXl5Wrt2rZYuXaqTJ0/qwIEDKigosJ7X7XYrLS1NU6dO1fTp07V161Y1NjZqyZIlkqSIiIhuZwEAAIHNryeqd2fLli0KCgpSamqqmpub5XK5tGPHDmt/cHCwjh49qhUrVsjpdGrw4MFKS0vTSy+9ZK0ZM2aMCgoKtHr1am3btk0jRozQ7t275XK5rDULFixQXV2dcnJy5PF4NHnyZBUWFvqcvN7dLAAAILD5/TpVgYTrVCFQcJ0qAPeTfnOdKgAAgPsBUQUAAGAAUQUAAGAAUQUAAGAAUQUAAGAAUQUAAGAAUQUAAGAAUQUAAGAAUQUAAGAAUQUAAGAAUQUAAGAAUQUAAGAAUQUAAGAAUQUAAGAAUQUAAGAAUQUAAGAAUQUAAGAAUQUAAGAAUQUAAGAAUQUAAGAAUQUAAGAAUQUAAGAAUQUAAGAAUQUAAGAAUQUAAGAAUQUAAGAAUQUAAGAAUQUAAGAAUQUAAGAAUQUAAGAAUQUAAGAAUQUAAGAAUQUAAGAAUQUAAGAAUQUAAGAAUQUAAGAAUQUAAGAAUQUAAGAAUQUAAGAAUQUAAGAAUQUAAGAAUQUAAGAAUQUAAGBAr6Lq0UcfVX19/W3bvV6vHn300a87EwAAQL/Tq6g6deqUWlpabtve1NSkt99++2sPBQAA0N8MuJPFv//9763//sMf/iCPx2Pdb21tVWFhof76r//a3HQAgD7PttHm7xFwD7Xntvt7hD7rjqJq8uTJstlsstlsXX7MFxYWpp/97GfGhgMAAOgv7iiqKisr1d7ergcffFClpaWKioqy9tntdkVHRys4ONj4kAAAAH3dHUXVqFGjJEltbW13ZRgAAID+6o6iqrOPPvpIv/3tb1VbW3tbZOXk5HztwQAAAPqTXkXVf/zHf2jFihUaPny4YmNjZbP9/5MUbTYbUQUAAAJOr6Lq5Zdf1r/+678qKyvL9DwAAAD9Uq+uU/XZZ59p/vz5X/vJd+7cqYkTJ8rhcMjhcMjpdOrYsWPW/qamJmVkZGjYsGEKDw9XamqqampqfI5RVVWllJQUDRo0SNHR0VqzZo1u3brls+bUqVOaMmWKQkJCNHbsWOXn5982y/bt2zV69GiFhoYqKSlJpaWlPvt7MgsAAAhcvYqq+fPn66233vraTz5ixAi98sorKisr0/vvv69HH31UzzzzjC5evChJWr16tY4cOaKDBw+quLhY1dXVmjt3rvX41tZWpaSkqKWlRWfOnNHrr7+u/Px8n48fKysrlZKSolmzZqm8vFyZmZlatmyZjh8/bq3Zv3+/3G63cnNzde7cOU2aNEkul0u1tbXWmu5mAQAAgc3W3t5+x1fx2rRpk376058qJSVFEyZM0MCBA332/+AHP+j1QJGRkXr11Vc1b948RUVFad++fZo3b54kqaKiQuPHj1dJSYlmzJihY8eO6amnnlJ1dbViYmIkSbt27VJWVpbq6upkt9uVlZWlgoICXbhwwXqOhQsXqr6+XoWFhZKkpKQkTZs2TXl5eZI+/3ZjfHy8Vq1apXXr1qmhoaHbWXrC6/UqIiJCDQ0Ncjgcvf4d9UdcHDCwcHHAwMLrO7AE4uu7p39/9+qcql/84hcKDw9XcXGxiouLffbZbLZeRVVra6sOHjyoxsZGOZ1OlZWV6ebNm0pOTrbWjBs3TiNHjrRCpqSkRBMmTLCCSpJcLpdWrFihixcv6tvf/rZKSkp8jtGxJjMzU5LU0tKisrIyZWdnW/uDgoKUnJyskpISSerRLF1pbm5Wc3Ozdd/r9d7x7wUAAPQPvYqqyspKYwOcP39eTqdTTU1NCg8P16FDh5SQkKDy8nLZ7XYNHTrUZ31MTIz1z+N4PB6foOrY37Hvq9Z4vV7duHFDn332mVpbW7tcU1FRYR2ju1m6smnTJm3cuLFnvwgAANCv9eqcKpO++c1vqry8XGfPntWKFSuUlpamP/zhD/4ey4js7Gw1NDRYt8uXL/t7JAAAcJf06p2qpUuXfuX+PXv29PhYdrtdY8eOlSQlJibqvffe07Zt27RgwQK1tLSovr7e5x2impoaxcbGSpJiY2Nv+5ZexzfyOq/54rf0ampq5HA4FBYWpuDgYAUHB3e5pvMxupulKyEhIQoJCenx7wIAAPRfvb6kQudbbW2tTp48qf/+7/9WfX391xqora1Nzc3NSkxM1MCBA1VUVGTtu3TpkqqqquR0OiVJTqdT58+f9/mW3okTJ+RwOJSQkGCt6XyMjjUdx7Db7UpMTPRZ09bWpqKiImtNT2YBAACBrVfvVB06dOi2bW1tbVqxYoX+5m/+psfHyc7O1hNPPKGRI0fq2rVr2rdvn06dOqXjx48rIiJC6enpcrvdioyMlMPh0KpVq+R0Oq0Tw2fPnq2EhAQtXrxYmzdvlsfj0fr165WRkWG9Q/TCCy8oLy9Pa9eu1dKlS3Xy5EkdOHBABQUF1hxut1tpaWmaOnWqpk+frq1bt6qxsVFLliyRpB7NAgAAAluv/+2/LwoKCpLb7dYjjzyitWvX9ugxtbW1eu6553TlyhVFRERo4sSJOn78uP7+7/9ekrRlyxYFBQUpNTVVzc3Ncrlc2rFjh/X44OBgHT16VCtWrJDT6dTgwYOVlpaml156yVozZswYFRQUaPXq1dq2bZtGjBih3bt3y+VyWWsWLFiguro65eTkyOPxaPLkySosLPQ5eb27WQAAQGDr1XWqvsxvfvMbpaWlqa6uztQh7ytcpwqBIhCvYxPIeH0HlkB8fd/V61S53W6f++3t7bpy5YoKCgqUlpbWm0MCAAD0a72Kqt/97nc+94OCghQVFaWf/OQn3X4zEAAA4H7Uq6j67W9/a3oOAACAfu1rnaheV1enS5cuSfr8Ip5RUVFGhgIAAOhvenWdqsbGRi1dulQPPPCAZs6cqZkzZyouLk7p6en6y1/+YnpGAACAPq9XUeV2u1VcXKwjR46ovr5e9fX1+vWvf63i4mL96Ec/Mj0jAABAn9erj//+67/+S7/61a/0yCOPWNuefPJJhYWF6Xvf+5527txpaj4AAIB+oVfvVP3lL3/xuTBmh+joaD7+AwAAAalXUeV0OpWbm6umpiZr240bN7Rx40b+LTwAABCQevXx39atW/X4449rxIgRmjRpkiTpgw8+UEhIiN566y2jAwIAAPQHvYqqCRMm6KOPPtIbb7yhiooKSdKzzz6rRYsWKSwszOiAAAAA/UGvomrTpk2KiYnR8uXLfbbv2bNHdXV1ysrKMjIcAABAf9Grc6p+/vOfa9y4cbdt/9a3vqVdu3Z97aEAAAD6m15Flcfj0QMPPHDb9qioKF25cuVrDwUAANDf9Cqq4uPj9c4779y2/Z133lFcXNzXHgoAAKC/6dU5VcuXL1dmZqZu3rypRx99VJJUVFSktWvXckV1AAAQkHoVVWvWrNGf//xn/eM//qNaWlokSaGhocrKylJ2drbRAQEAAPqDXkWVzWbTv/3bv+nHP/6xPvzwQ4WFhemhhx5SSEiI6fkAAAD6hV5FVYfw8HBNmzbN1CwAAAD9Vq9OVAcAAIAvogoAAMAAogoAAMAAogoAAMAAogoAAMAAogoAAMAAogoAAMAAogoAAMAAogoAAMAAogoAAMAAogoAAMAAogoAAMAAogoAAMAAogoAAMAAogoAAMAAogoAAMAAogoAAMAAogoAAMAAogoAAMAAogoAAMAAogoAAMAAogoAAMAAogoAAMAAogoAAMAAogoAAMAAogoAAMAAogoAAMAAogoAAMAAogoAAMAAogoAAMAAogoAAMAAogoAAMAAogoAAMAAv0bVpk2bNG3aNA0ZMkTR0dGaM2eOLl265LOmqalJGRkZGjZsmMLDw5WamqqamhqfNVVVVUpJSdGgQYMUHR2tNWvW6NatWz5rTp06pSlTpigkJERjx45Vfn7+bfNs375do0ePVmhoqJKSklRaWnrHswAAgMDk16gqLi5WRkaG3n33XZ04cUI3b97U7Nmz1djYaK1ZvXq1jhw5ooMHD6q4uFjV1dWaO3eutb+1tVUpKSlqaWnRmTNn9Prrrys/P185OTnWmsrKSqWkpGjWrFkqLy9XZmamli1bpuPHj1tr9u/fL7fbrdzcXJ07d06TJk2Sy+VSbW1tj2cBAACBy9be3t7u7yE61NXVKTo6WsXFxZo5c6YaGhoUFRWlffv2ad68eZKkiooKjR8/XiUlJZoxY4aOHTump556StXV1YqJiZEk7dq1S1lZWaqrq5PdbldWVpYKCgp04cIF67kWLlyo+vp6FRYWSpKSkpI0bdo05eXlSZLa2toUHx+vVatWad26dT2apTter1cRERFqaGiQw+Ew+rvr62wbbf4eAfdQe26f+WMF9wCv78ASiK/vnv793afOqWpoaJAkRUZGSpLKysp08+ZNJScnW2vGjRunkSNHqqSkRJJUUlKiCRMmWEElSS6XS16vVxcvXrTWdD5Gx5qOY7S0tKisrMxnTVBQkJKTk601PZnli5qbm+X1en1uAADg/tRnoqqtrU2ZmZn6u7/7Oz388MOSJI/HI7vdrqFDh/qsjYmJkcfjsdZ0DqqO/R37vmqN1+vVjRs3dPXqVbW2tna5pvMxupvlizZt2qSIiAjrFh8f38PfBgAA6G/6TFRlZGTowoULevPNN/09ijHZ2dlqaGiwbpcvX/b3SAAA4C4Z4O8BJGnlypU6evSoTp8+rREjRljbY2Nj1dLSovr6ep93iGpqahQbG2ut+eK39Dq+kdd5zRe/pVdTUyOHw6GwsDAFBwcrODi4yzWdj9HdLF8UEhKikJCQO/hNAACA/sqv71S1t7dr5cqVOnTokE6ePKkxY8b47E9MTNTAgQNVVFRkbbt06ZKqqqrkdDolSU6nU+fPn/f5lt6JEyfkcDiUkJBgrel8jI41Hcew2+1KTEz0WdPW1qaioiJrTU9mAQAAgcuv71RlZGRo3759+vWvf60hQ4ZY5yZFREQoLCxMERERSk9Pl9vtVmRkpBwOh1atWiWn02l922727NlKSEjQ4sWLtXnzZnk8Hq1fv14ZGRnWu0QvvPCC8vLytHbtWi1dulQnT57UgQMHVFBQYM3idruVlpamqVOnavr06dq6dasaGxu1ZMkSa6buZgEAAIHLr1G1c+dOSdIjjzzis33v3r16/vnnJUlbtmxRUFCQUlNT1dzcLJfLpR07dlhrg4ODdfToUa1YsUJOp1ODBw9WWlqaXnrpJWvNmDFjVFBQoNWrV2vbtm0aMWKEdu/eLZfLZa1ZsGCB6urqlJOTI4/Ho8mTJ6uwsNDn5PXuZgEAAIGrT12n6n7HdaoQKALxOjaBjNd3YAnE13e/vE4VAABAf0VUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGEBUAQAAGODXqDp9+rSefvppxcXFyWaz6fDhwz7729vblZOTowceeEBhYWFKTk7WRx995LPm008/1aJFi+RwODR06FClp6fr+vXrPmt+//vf67vf/a5CQ0MVHx+vzZs33zbLwYMHNW7cOIWGhmrChAn6zW9+c8ezAACAwOXXqGpsbNSkSZO0ffv2Lvdv3rxZr732mnbt2qWzZ89q8ODBcrlcampqstYsWrRIFy9e1IkTJ3T06FGdPn1a3//+9639Xq9Xs2fP1qhRo1RWVqZXX31VGzZs0C9+8QtrzZkzZ/Tss88qPT1dv/vd7zRnzhzNmTNHFy5cuKNZAABA4LK1t7e3+3sISbLZbDp06JDmzJkj6fN3huLi4vSjH/1IL774oiSpoaFBMTExys/P18KFC/Xhhx8qISFB7733nqZOnSpJKiws1JNPPqlPPvlEcXFx2rlzp/75n/9ZHo9HdrtdkrRu3TodPnxYFRUVkqQFCxaosbFRR48eteaZMWOGJk+erF27dvVolp7wer2KiIhQQ0ODHA6Hkd9bf2HbaPP3CLiH2nP7xB8ruEd4fQeWQHx99/Tv7z57TlVlZaU8Ho+Sk5OtbREREUpKSlJJSYkkqaSkREOHDrWCSpKSk5MVFBSks2fPWmtmzpxpBZUkuVwuXbp0SZ999pm1pvPzdKzpeJ6ezNKV5uZmeb1enxsAALg/9dmo8ng8kqSYmBif7TExMdY+j8ej6Ohon/0DBgxQZGSkz5qujtH5Ob5sTef93c3SlU2bNikiIsK6xcfHd/NTAwCA/qrPRtX9IDs7Ww0NDdbt8uXL/h4JAADcJX02qmJjYyVJNTU1PttramqsfbGxsaqtrfXZf+vWLX366ac+a7o6Rufn+LI1nfd3N0tXQkJC5HA4fG4AAOD+1GejasyYMYqNjVVRUZG1zev16uzZs3I6nZIkp9Op+vp6lZWVWWtOnjyptrY2JSUlWWtOnz6tmzdvWmtOnDihb37zm/qrv/ora03n5+lY0/E8PZkFAAAENr9G1fXr11VeXq7y8nJJn58QXl5erqqqKtlsNmVmZurll1/W//zP/+j8+fN67rnnFBcXZ31DcPz48Xr88ce1fPlylZaW6p133tHKlSu1cOFCxcXFSZL+4R/+QXa7Xenp6bp48aL279+vbdu2ye12W3P88Ic/VGFhoX7yk5+ooqJCGzZs0Pvvv6+VK1dKUo9mAQAAgW2AP5/8/fff16xZs6z7HaGTlpam/Px8rV27Vo2Njfr+97+v+vp6fec731FhYaFCQ0Otx7zxxhtauXKlHnvsMQUFBSk1NVWvvfaatT8iIkJvvfWWMjIylJiYqOHDhysnJ8fnWlZ/+7d/q3379mn9+vX6p3/6Jz300EM6fPiwHn74YWtNT2YBAACBq89cpyoQcJ0qBIpAvI5NIOP1HVgC8fXd769TBQAA0J8QVQAAAAYQVQAAAAYQVQAAAAYQVQAAAAYQVQAAAAYQVQAAAAYQVQAAAAYQVQAAAAYQVQAAAAYQVQAAAAYQVQAAAAYQVQAAAAYQVQAAAAYQVQAAAAYQVQAAAAYQVQAAAAYQVQAAAAYQVQAAAAYQVQAAAAYQVQAAAAYQVQAAAAYQVQAAAAYQVQAAAAYQVQAAAAYQVQAAAAYQVQAAAAYQVQAAAAYQVQAAAAYQVQAAAAYQVQAAAAYQVQAAAAYQVQAAAAYQVQAAAAYQVQAAAAYQVQAAAAYQVQAAAAYQVQAAAAYQVQAAAAYQVQAAAAYQVQAAAAYQVQAAAAYQVQAAAAYQVQAAAAYQVQAAAAYQVQAAAAYQVQAAAAYQVQAAAAYQVQAAAAYQVQAAAAYQVQAAAAYQVQAAAAYQVXdo+/btGj16tEJDQ5WUlKTS0lJ/jwQAAPoAouoO7N+/X263W7m5uTp37pwmTZokl8ul2tpaf48GAAD8jKi6Az/96U+1fPlyLVmyRAkJCdq1a5cGDRqkPXv2+Hs0AADgZwP8PUB/0dLSorKyMmVnZ1vbgoKClJycrJKSki4f09zcrObmZut+Q0ODJMnr9d7dYfuiJn8PgHspIP8/Hsh4fQeUQHx9d/zM7e3tX7mOqOqhq1evqrW1VTExMT7bY2JiVFFR0eVjNm3apI0bN962PT4+/q7MCPQVEa9E+HsEAHdJIL++r127poiIL//5iaq7KDs7W26327rf1tamTz/9VMOGDZPNZvPjZLgXvF6v4uPjdfnyZTkcDn+PA8AgXt+Bpb29XdeuXVNcXNxXriOqemj48OEKDg5WTU2Nz/aamhrFxsZ2+ZiQkBCFhIT4bBs6dOjdGhF9lMPh4A9d4D7F6ztwfNU7VB04Ub2H7Ha7EhMTVVRUZG1ra2tTUVGRnE6nHycDAAB9Ae9U3QG32620tDRNnTpV06dP19atW9XY2KglS5b4ezQAAOBnRNUdWLBggerq6pSTkyOPx6PJkyersLDwtpPXAenzj39zc3Nv+wgYQP/H6xtdsbV39/1AAAAAdItzqgAAAAwgqgAAAAwgqgAAAAwgqgAAAAwgqoC7YPv27Ro9erRCQ0OVlJSk0tJSf48EwIDTp0/r6aefVlxcnGw2mw4fPuzvkdCHEFWAYfv375fb7VZubq7OnTunSZMmyeVyqba21t+jAfiaGhsbNWnSJG3fvt3fo6AP4pIKgGFJSUmaNm2a8vLyJH1+5f34+HitWrVK69at8/N0AEyx2Ww6dOiQ5syZ4+9R0EfwThVgUEtLi8rKypScnGxtCwoKUnJyskpKSvw4GQDgbiOqAIOuXr2q1tbW266yHxMTI4/H46epAAD3AlEFAABgAFEFGDR8+HAFBwerpqbGZ3tNTY1iY2P9NBUA4F4gqgCD7Ha7EhMTVVRUZG1ra2tTUVGRnE6nHycDANxtA/w9AHC/cbvdSktL09SpUzV9+nRt3bpVjY2NWrJkib9HA/A1Xb9+XR9//LF1v7KyUuXl5YqMjNTIkSP9OBn6Ai6pANwFeXl5evXVV+XxeDR58mS99tprSkpK8vdYAL6mU6dOadasWbdtT0tLU35+/r0fCH0KUQUAAGAA51QBAAAYQFQBAAAYQFQBAAAYQFQBAAAYQFQBAAAYQFQBAAAYQFQBAAAYQFQBAAAYQFQBAAAYQFQBwBc88sgjyszM9PcYAPoZogoAAMAAogoAOnn++edVXFysbdu2yWazyWazacCAAfr3f/93n3Xl5eWy2Wz6+OOPJUk2m007d+7UE088obCwMD344IP61a9+5fOYy5cv63vf+56GDh2qyMhIPfPMM/rTn/50r340AHcZUQUAnWzbtk1Op1PLly/XlStXdOXKFW3cuFF79+71Wbd3717NnDlTY8eOtbb9+Mc/Vmpqqj744AMtWrRICxcu1IcffihJunnzplwul4YMGaK3335b77zzjsLDw/X444+rpaXlnv6MAO4OogoAOomIiJDdbtegQYMUGxur2NhYLVmyRJcuXVJpaamkzwNp3759Wrp0qc9j58+fr2XLlukb3/iG/uVf/kVTp07Vz372M0nS/v371dbWpt27d2vChAkaP3689u7dq6qqKp06depe/5gA7gKiCgC6ERcXp5SUFO3Zs0eSdOTIETU3N2v+/Pk+65xO5233O96p+uCDD/Txxx9ryJAhCg8PV3h4uCIjI9XU1KQ//vGP9+YHAXBXDfD3AADQHyxbtkyLFy/Wli1btHfvXi1YsECDBg3q8eOvX7+uxMREvfHGG7fti4qKMjkqAD8hqgDgC+x2u1pbW322Pfnkkxo8eLB27typwsJCnT59+rbHvfvuu3ruued87n/729+WJE2ZMkX79+9XdHS0HA7H3f0BAPgFH/8BwBeMHj1aZ8+e1Z/+9CddvXpVbW1tCg4O1vPPP6/s7Gw99NBDt33UJ0kHDx7Unj179H//93/Kzc1VaWmpVq5cKUlatGiRhg8frmeeeUZvv/22KisrderUKf3gBz/QJ598cq9/RAB3AVEFAF/w4osvKjg4WAkJCYqKilJVVZUkKT09XS0tLVqyZEmXj9u4caPefPNNTZw4Uf/5n/+pX/7yl0pISJAkDRo0SKdPn9bIkSM1d+5cjR8/Xunp6WpqauKdK+A+YWtvb2/39xAA0B+8/fbbeuyxx3T58mXFxMT47LPZbDp06JDmzJnjn+EA+B3nVAFAN5qbm1VXV6cNGzZo/vz5twUVAEh8/AcA3frlL3+pUaNGqb6+Xps3b/b3OAD6KD7+AwAAMIB3qgAAAAwgqgAAAAwgqgAAAAwgqgAAAAwgqgAAAAwgqgAAAAwgqgAAAAwgqgAAAAz4fykKgcbmXdZ4AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df=pd.read_csv('dataset.csv')\n",
    "df.dropna(inplace=True)\n",
    "type_counts=df['type'].value_counts()\n",
    "type_counts.plot(kind='bar',rot=0,color='green')\n",
    "plt.xlabel('type')\n",
    "plt.ylabel('count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=list(df['url'])\n",
    "Type=list(df['type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=np.array(Type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_spaces_around_punctuation(input_list):\n",
    "    translation_table = str.maketrans({key: f' {key} ' for key in string.punctuation})\n",
    "    result_list = [s.translate(translation_table) for s in input_list]\n",
    "    result_list = [s.split() for s in result_list]\n",
    "\n",
    "    return result_list\n",
    "\n",
    "output_list = add_spaces_around_punctuation(url)\n",
    "\n",
    "\n",
    "output_string = ' '.join([' '.join(words) for words in output_list])\n",
    "\n",
    "\n",
    "output_string = output_string.replace('[', '').replace(']', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "alist=output_string.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = Counter(alist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = sorted(counts, key=counts.get, reverse=True)\n",
    "vocab_to_int = {word: ii for ii, word in enumerate(vocab, 1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_ints = []\n",
    "for review in output_list:\n",
    "    reviews_ints.append([vocab_to_int.get(word, 0) for word in review])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "364\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "lengths = [len(sublist) for sublist in reviews_ints]\n",
    "\n",
    "max_length = max(lengths)\n",
    "min_length=min(lengths)\n",
    "print(max_length)\n",
    "print(min_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_features(reviews_ints, seq_length):\n",
    "\n",
    "\n",
    "    # getting the correct rows x cols shape\n",
    "    features = np.zeros((len(reviews_ints), seq_length), dtype=int)\n",
    "\n",
    "    # for each review, I grab that review and\n",
    "    for i, row in enumerate(reviews_ints):\n",
    "        features[i, -len(row):] = np.array(row)[:seq_length]\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   8   4   1   1   6   2\n",
      " 140   2   5   1]\n"
     ]
    }
   ],
   "source": [
    "seq_length = 364\n",
    "features = pad_features(reviews_ints, seq_length=seq_length)\n",
    "assert len(features)==len(reviews_ints), \"Your features should have as many rows as reviews.\"\n",
    "assert len(features[0])==seq_length, \"Each feature row should contain seq_length values.\"\n",
    "print(features[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\tFeature Shapes:\n",
      "Train set: \t\t(700900, 364) \n",
      "Validation set: \t(17500, 364) \n",
      "Test set: \t\t(157700, 364)\n"
     ]
    }
   ],
   "source": [
    "split_frac = 0.8\n",
    "split_idx = int(len(features)*split_frac)\n",
    "train_x, remaining_x = features[:split_idx], features[split_idx:]\n",
    "train_y, remaining_y = labels[:split_idx], labels[split_idx:]\n",
    "\n",
    "test_idx = int(len(remaining_x)*0.1)\n",
    "val_x, test_x = remaining_x[:test_idx], remaining_x[test_idx:]\n",
    "val_y, test_y = remaining_y[:test_idx], remaining_y[test_idx:]\n",
    "\n",
    "train_x=train_x[:-85]\n",
    "train_y=train_y[:-85]\n",
    "val_x=val_x[:-24]\n",
    "val_y=val_y[:-24]\n",
    "test_x=test_x[:-23]\n",
    "test_y=test_y[:-23]\n",
    "\n",
    "\n",
    "print(\"\\t\\t\\tFeature Shapes:\")\n",
    "print(\"Train set: \\t\\t{}\".format(train_x.shape),\n",
    "      \"\\nValidation set: \\t{}\".format(val_x.shape),\n",
    "      \"\\nTest set: \\t\\t{}\".format(test_x.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
    "valid_data = TensorDataset(torch.from_numpy(val_x), torch.from_numpy(val_y))\n",
    "test_data = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\n",
    "\n",
    "batch_size=100\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on GPU.\n"
     ]
    }
   ],
   "source": [
    "train_on_gpu=torch.cuda.is_available()\n",
    "\n",
    "if(train_on_gpu):\n",
    "    print('Training on GPU.')\n",
    "else:\n",
    "    print('No GPU available, training on CPU.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class malicious(nn.Module):\n",
    "  def __init__(self,vocab_size,output_size,embedding_dim,hidden_dim,n_layers,drop_prob=0.5):\n",
    "    super(malicious,self).__init__()\n",
    "    self.output_size=output_size\n",
    "    self.n_layers=n_layers\n",
    "    self.hidden_dim=hidden_dim\n",
    "    self.embedding=nn.Embedding(vocab_size,embedding_dim)\n",
    "    self.lstm=nn.LSTM(embedding_dim,hidden_dim,n_layers,dropout=drop_prob,batch_first=True)\n",
    "    self.dropout = nn.Dropout(0.3)\n",
    "    self.fc=nn.Linear(hidden_dim,output_size)\n",
    "\n",
    "  def forward(self,x,hidden):\n",
    "    batch_size=x.size(0)\n",
    "    x=x.long()\n",
    "    embeds=self.embedding(x)\n",
    "    lstm_out,hidden=self.lstm(embeds,hidden)\n",
    "    lstm_out=lstm_out[:, -1, :] # getting the last time step output\n",
    "    output=self.dropout(lstm_out)\n",
    "    output=F.sigmoid(self.fc(output))\n",
    "    return output,hidden\n",
    "\n",
    "  def init_hidden(self, batch_size):\n",
    "    weight = next(self.parameters()).data\n",
    "    if (train_on_gpu):\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
    "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
    "    else:\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
    "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
    "\n",
    "    return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "malicious(\n",
      "  (embedding): Embedding(650291, 400)\n",
      "  (lstm): LSTM(400, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "vocab_size=len(vocab_to_int)+1 # +1 for the 0 padding + our word tokens\n",
    "output_size=1\n",
    "embedding_dim=400\n",
    "hidden_dim=256\n",
    "n_layers=2\n",
    "\n",
    "model=malicious(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion=nn.BCELoss()\n",
    "optimizer=optim.Adam(model.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-12 20:46:45,395] A new study created in memory with name: no-name-69efc41e-a6df-437c-9a35-697ea43c105a\n",
      "[I 2024-02-12 22:05:17,342] Trial 0 finished with value: 0.07219779255234503 and parameters: {'embedding_dim': 453, 'hidden_dim': 212, 'n_layers': 3, 'drop_prob': 0.22667268160734158}. Best is trial 0 with value: 0.07219779255234503.\n",
      "c:\\Users\\Ryzen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.22714807894987155 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "[I 2024-02-12 22:49:23,515] Trial 1 finished with value: 0.06146158152027056 and parameters: {'embedding_dim': 325, 'hidden_dim': 238, 'n_layers': 1, 'drop_prob': 0.22714807894987155}. Best is trial 1 with value: 0.06146158152027056.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials:  2\n",
      "Best trial:\n",
      "  Value:  0.06146158152027056\n",
      "  Params: \n",
      "    embedding_dim: 325\n",
      "    hidden_dim: 238\n",
      "    n_layers: 1\n",
      "    drop_prob: 0.22714807894987155\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    # Define the search space for hyperparameters\n",
    "    embedding_dim = trial.suggest_int('embedding_dim', 300, 500)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 200, 400)\n",
    "    n_layers=trial.suggest_int('n_layers',1,3)\n",
    "    drop_prob = trial.suggest_float('drop_prob', 0.1, 0.5)\n",
    "\n",
    "    # Build the model with suggested hyperparameters\n",
    "    model = malicious(vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob)\n",
    "\n",
    "    # Define optimizer and criterion\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.BCELoss()\n",
    "\n",
    "    if(train_on_gpu):\n",
    "        model.cuda()\n",
    "\n",
    "    # Training loop\n",
    "    epochs=4\n",
    "    counter=0\n",
    "    clip=5\n",
    "    for e in range(epochs):\n",
    "        model.train()\n",
    "        h = model.init_hidden(batch_size)\n",
    "        for Features, Labels in train_loader:\n",
    "            counter += 1\n",
    "            if(train_on_gpu):\n",
    "                Features, Labels = Features.cuda(), Labels.cuda()\n",
    "            h = tuple([each.data for each in h])\n",
    "            model.zero_grad()\n",
    "            output, h = model(Features, h)\n",
    "            loss = criterion(output.squeeze(), Labels.float())\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "            optimizer.step()\n",
    "\n",
    "    # Validation loop\n",
    "    val_losses = []\n",
    "    model.eval()\n",
    "    for Features, Labels in valid_loader:\n",
    "        val_h = model.init_hidden(batch_size)\n",
    "        val_h = tuple([each.data for each in val_h])\n",
    "        if(train_on_gpu):\n",
    "            Features, Labels = Features.cuda(), Labels.cuda()\n",
    "        output, val_h = model(Features, val_h)\n",
    "        val_loss = criterion(output.squeeze(), Labels.float())\n",
    "        val_losses.append(val_loss.item())\n",
    "\n",
    "    return np.mean(val_losses)\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=2)  \n",
    "\n",
    "print(\"Number of finished trials: \", len(study.trials))\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(\"  Value: \", trial.value)\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
